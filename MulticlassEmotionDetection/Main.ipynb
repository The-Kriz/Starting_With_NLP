{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Importing Library Modules"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neattext.functions as nfx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importing DataSet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\robolab\\NLP_setv\\MulticlassEmotionDetection\n"
     ]
    }
   ],
   "source": [
    "# Current directory\n",
    "print(os.getcwd())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\".\\Dataset\\emotion-dataset.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "   Emotion                                               Text\n0  neutral                                             Why ? \n1      joy    Sage Act upgrade on my to do list for tommorow.\n2  sadness  ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Emotion</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>neutral</td>\n      <td>Why ?</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>joy</td>\n      <td>Sage Act upgrade on my to do list for tommorow.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sadness</td>\n      <td>ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "joy         11045\nsadness      6722\nfear         5410\nanger        4297\nsurprise     4062\nneutral      2254\ndisgust       856\nshame         146\nName: Emotion, dtype: int64"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Emotion\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "['BTC_ADDRESS_REGEX',\n 'CURRENCY_REGEX',\n 'CURRENCY_SYMB_REGEX',\n 'Counter',\n 'DATE_REGEX',\n 'EMAIL_REGEX',\n 'EMOJI_REGEX',\n 'HASTAG_REGEX',\n 'MASTERCard_REGEX',\n 'MD5_SHA_REGEX',\n 'MOST_COMMON_PUNCT_REGEX',\n 'NUMBERS_REGEX',\n 'PHONE_REGEX',\n 'PoBOX_REGEX',\n 'SPECIAL_CHARACTERS_REGEX',\n 'STOPWORDS',\n 'STOPWORDS_de',\n 'STOPWORDS_en',\n 'STOPWORDS_es',\n 'STOPWORDS_fr',\n 'STOPWORDS_ru',\n 'STOPWORDS_yo',\n 'STREET_ADDRESS_REGEX',\n 'TextFrame',\n 'URL_PATTERN',\n 'USER_HANDLES_REGEX',\n 'VISACard_REGEX',\n '__builtins__',\n '__cached__',\n '__doc__',\n '__file__',\n '__generate_text',\n '__loader__',\n '__name__',\n '__numbers_dict',\n '__package__',\n '__spec__',\n '_lex_richness_herdan',\n '_lex_richness_maas_ttr',\n 'clean_text',\n 'defaultdict',\n 'digit2words',\n 'extract_btc_address',\n 'extract_currencies',\n 'extract_currency_symbols',\n 'extract_dates',\n 'extract_emails',\n 'extract_emojis',\n 'extract_hashtags',\n 'extract_html_tags',\n 'extract_mastercard_addr',\n 'extract_md5sha',\n 'extract_numbers',\n 'extract_pattern',\n 'extract_phone_numbers',\n 'extract_postoffice_box',\n 'extract_shortwords',\n 'extract_special_characters',\n 'extract_stopwords',\n 'extract_street_address',\n 'extract_terms_in_bracket',\n 'extract_urls',\n 'extract_userhandles',\n 'extract_visacard_addr',\n 'fix_contractions',\n 'generate_sentence',\n 'hamming_distance',\n 'inverse_df',\n 'lexical_richness',\n 'markov_chain',\n 'math',\n 'nlargest',\n 'normalize',\n 'num2words',\n 'random',\n 're',\n 'read_txt',\n 'remove_accents',\n 'remove_bad_quotes',\n 'remove_btc_address',\n 'remove_currencies',\n 'remove_currency_symbols',\n 'remove_custom_pattern',\n 'remove_custom_words',\n 'remove_dates',\n 'remove_emails',\n 'remove_emojis',\n 'remove_hashtags',\n 'remove_html_tags',\n 'remove_mastercard_addr',\n 'remove_md5sha',\n 'remove_multiple_spaces',\n 'remove_non_ascii',\n 'remove_numbers',\n 'remove_phone_numbers',\n 'remove_postoffice_box',\n 'remove_puncts',\n 'remove_punctuations',\n 'remove_shortwords',\n 'remove_special_characters',\n 'remove_stopwords',\n 'remove_street_address',\n 'remove_terms_in_bracket',\n 'remove_urls',\n 'remove_userhandles',\n 'remove_visacard_addr',\n 'replace_bad_quotes',\n 'replace_currencies',\n 'replace_currency_symbols',\n 'replace_dates',\n 'replace_emails',\n 'replace_emojis',\n 'replace_numbers',\n 'replace_phone_numbers',\n 'replace_special_characters',\n 'replace_term',\n 'replace_urls',\n 'string',\n 'term_freq',\n 'to_txt',\n 'unicodedata',\n 'word_freq',\n 'word_length_freq']"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(nfx)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "data": {
      "text/plain": "\"@Iluvmiasantos ugh babe.. hugggzzz for u .!  babe naamazed nga ako e babe e, despite nega's mas pinaramdam at fil ko ang \""
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'][4]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [
    {
     "data": {
      "text/plain": "\"  ugh babe.. hugggzzz for u .!  babe naamazed nga ako e babe e, despite nega's mas pinaramdam at fil ko ang \""
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing user name/ Tag from the dataset\n",
    "df['Clean_Text'] = df['Text'].apply(nfx.remove_userhandles)\n",
    "df['Clean_Text'][4]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [],
   "source": [
    "# Removing Stop Words\n",
    "df['Clean_Text'] = df['Clean_Text'].apply(nfx.remove_stopwords)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "data": {
      "text/plain": "   Emotion                                         Clean_Text\n0  neutral                                                  ?\n1      joy                    Sage Act upgrade list tommorow.\n2  sadness  WAY HOMEGIRL BABY FUNERAL!!! MAN HATE FUNERALS...\n3      joy  eye ! true hazel eye-and brilliant ! Regular f...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Emotion</th>\n      <th>Clean_Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>neutral</td>\n      <td>?</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>joy</td>\n      <td>Sage Act upgrade list tommorow.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sadness</td>\n      <td>WAY HOMEGIRL BABY FUNERAL!!! MAN HATE FUNERALS...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>joy</td>\n      <td>eye ! true hazel eye-and brilliant ! Regular f...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessed DataSet\n",
    "df[['Emotion','Clean_Text']].head(4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importing machine learning packages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [
    "# Assigning X and Y from Dataset\n",
    "Xfeatures = df['Clean_Text']\n",
    "ylabels = df['Emotion']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [
    "# Spliting Dataset\n",
    "x_train,x_test,y_train,y_test = train_test_split(Xfeatures,ylabels,test_size=0.3,random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [],
   "source": [
    "# Bag of words\n",
    "#countvector = CountVectorizer(ngram_range=(1,1))\n",
    "countvector = CountVectorizer(ngram_range=(1,2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [],
   "source": [
    "trainDataset = countvector.fit_transform(x_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [],
   "source": [
    "#trainDataset.toarray()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression(max_iter=1000, solver='liblinear')"
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Logistic Regression model\n",
    "logreg = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "logreg.fit(trainDataset, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "testDataset = countvector.transform(x_test)\n",
    "y_pred = logreg.predict(testDataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6403525579612953\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Trial"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger' 'joy' 'sadness' 'neutral' 'sadness' 'sadness' 'surprise']\n"
     ]
    }
   ],
   "source": [
    "input= ['i will kill him','i got full mark','i am feeling depressed','hi im hari','tickets are sold out','you will lose marks','he is actually excited about milan']\n",
    "input_countvector = countvector.transform(input)\n",
    "predictions = logreg.predict(input_countvector)\n",
    "print(predictions)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kill', 'got mark', 'feeling depressed', 'hi im hari', 'tickets sold', 'lose marks', 'actually excited milan']\n",
      "['neutral' 'joy' 'sadness' 'neutral' 'neutral' 'fear' 'surprise']\n"
     ]
    }
   ],
   "source": [
    "input= ['i will kill him','i got full mark','i am feeling depressed','hi im hari','tickets are sold out','you will lose marks','he is actually excited about milan']\n",
    "\n",
    "for i in range(0,len(input)):\n",
    "    sentences = nfx.remove_stopwords(input[i])\n",
    "    input[i] = sentences\n",
    "print(input)\n",
    "input_countvector = countvector.transform(input)\n",
    "predictions = logreg.predict(input_countvector)\n",
    "print(predictions)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}